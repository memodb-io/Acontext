---
title: Multi-modal Messages
description: "Store messages with images, audio, and documents"
---

Acontext stores multi-modal content (images, audio, PDFs) as base64 within message parts. Format conversion between OpenAI and Anthropic is automatic.

## Images

<Tabs>
<Tab title="OpenAI Format">

```python
import os
import base64
from acontext import AcontextClient

client = AcontextClient(api_key=os.getenv("ACONTEXT_API_KEY"))
session = client.sessions.create()

# From URL
client.sessions.store_message(
    session_id=session.id,
    blob={
        "role": "user",
        "content": [
            {"type": "text", "text": "What's in this image?"},
            {"type": "image_url", "image_url": {"url": "https://example.com/image.png"}}
        ]
    },
    format="openai"
)

# From base64
with open("image.png", "rb") as f:
    image_data = base64.b64encode(f.read()).decode("utf-8")

client.sessions.store_message(
    session_id=session.id,
    blob={
        "role": "user",
        "content": [
            {"type": "text", "text": "Describe this"},
            {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{image_data}"}}
        ]
    },
    format="openai"
)
```
</Tab>

<Tab title="Anthropic Format">

```python
import os
import base64
from acontext import AcontextClient

client = AcontextClient(api_key=os.getenv("ACONTEXT_API_KEY"))
session = client.sessions.create()

with open("image.png", "rb") as f:
    image_data = base64.b64encode(f.read()).decode("utf-8")

client.sessions.store_message(
    session_id=session.id,
    blob={
        "role": "user",
        "content": [
            {"type": "text", "text": "Describe this image"},
            {
                "type": "image",
                "source": {"type": "base64", "media_type": "image/png", "data": image_data}
            }
        ]
    },
    format="anthropic"
)
```
</Tab>
</Tabs>

## Audio

```python
import base64

with open("audio.wav", "rb") as f:
    audio_data = base64.b64encode(f.read()).decode("utf-8")

client.sessions.store_message(
    session_id=session.id,
    blob={
        "role": "user",
        "content": [
            {"type": "text", "text": "Transcribe this audio"},
            {"type": "input_audio", "input_audio": {"data": audio_data, "format": "wav"}}
        ]
    },
    format="openai"
)
```

## Documents

<Tabs>
<Tab title="OpenAI Format">

```python
import base64

with open("document.pdf", "rb") as f:
    pdf_data = base64.b64encode(f.read()).decode("utf-8")

client.sessions.store_message(
    session_id=session.id,
    blob={
        "role": "user",
        "content": [
            {"type": "text", "text": "Summarize this PDF"},
            {"type": "file", "file": {"file_data": pdf_data, "filename": "document.pdf"}}
        ]
    },
    format="openai"
)
```
</Tab>

<Tab title="Anthropic Format">

```python
import base64

with open("report.pdf", "rb") as f:
    pdf_data = base64.b64encode(f.read()).decode("utf-8")

client.sessions.store_message(
    session_id=session.id,
    blob={
        "role": "user",
        "content": [
            {"type": "document", "source": {"type": "base64", "media_type": "application/pdf", "data": pdf_data}},
            {"type": "text", "text": "Summarize the key findings"}
        ]
    },
    format="anthropic"
)
```
</Tab>
</Tabs>

## Retrieve Messages

Base64 content is returned as-is. Format conversion is automatic:

```python
# Store as Anthropic, retrieve as OpenAI
result = client.sessions.get_messages(session_id=session.id, format="openai")

for msg in result.items:
    for part in msg.content:
        print(f"Type: {part.get('type')}")
```

## Next Steps

<CardGroup cols={2}>
<Card title="Store Artifacts" icon="box" href="/store/disk">
Store file artifacts alongside messages
</Card>
<Card title="Dashboard" icon="chart-simple" href="/observe/dashboard">
View messages in the dashboard
</Card>
</CardGroup>
