---
title: "Skill Content Tools"
description: "Enable LLMs to read skill files without sandbox"
---

Lightweight tools for LLMs to access skill content through function calling. Use when skills contain only reference content (no scripts to execute).

<Note>
For skills with executable scripts, use [Sandbox Tools with mounted skills](/tool/bash_tools#mounting-skills) instead.
</Note>

## Available Tools

| Tool | Description |
|------|-------------|
| `get_skill` | Get skill metadata and file index |
| `get_skill_file` | Read a file from a skill |

## Quick Start

<CodeGroup>
```python Python
import json
import os
from acontext import AcontextClient
from acontext.agent.skill import SKILL_TOOLS
from openai import OpenAI

client = AcontextClient(api_key=os.getenv("ACONTEXT_API_KEY"))
openai_client = OpenAI()

# Preload skills by UUID
skill_ids = ["uuid-of-skill-1", "uuid-of-skill-2"]
ctx = SKILL_TOOLS.format_context(client, skill_ids)

tools = SKILL_TOOLS.to_openai_tool_schema()
skills_context = ctx.get_context_prompt()

messages = [
    {"role": "system", "content": f"You have skill access.\n\n{skills_context}"},
    {"role": "user", "content": "What guidelines are in the internal-comms skill?"}
]

# Agent loop
while True:
    response = openai_client.chat.completions.create(
        model="gpt-4.1", messages=messages, tools=tools
    )
    message = response.choices[0].message
    messages.append(message)

    if not message.tool_calls:
        print(f"Assistant: {message.content}")
        break

    for tc in message.tool_calls:
        result = SKILL_TOOLS.execute_tool(ctx, tc.function.name, json.loads(tc.function.arguments))
        messages.append({"role": "tool", "tool_call_id": tc.id, "content": result})
```

```typescript TypeScript
import { AcontextClient, SKILL_TOOLS } from '@acontext/acontext';
import OpenAI from 'openai';

const client = new AcontextClient({
    apiKey: process.env.ACONTEXT_API_KEY,
});
const openai = new OpenAI();

// Preload skills by UUID
const skillIds = ["uuid-of-skill-1", "uuid-of-skill-2"];
const ctx = await SKILL_TOOLS.formatContext(client, skillIds);

const tools = SKILL_TOOLS.toOpenAIToolSchema();
const skillsContext = ctx.getContextPrompt();

const messages: OpenAI.ChatCompletionMessageParam[] = [
    { role: "system", content: `You have skill access.\n\n${skillsContext}` },
    { role: "user", content: "What guidelines are in the internal-comms skill?" },
];

// Agent loop
while (true) {
    const response = await openai.chat.completions.create({
        model: "gpt-4.1",
        messages,
        tools,
    });
    const message = response.choices[0].message;
    messages.push(message);

    if (!message.tool_calls) {
        console.log(`Assistant: ${message.content}`);
        break;
    }

    for (const tc of message.tool_calls) {
        const result = await SKILL_TOOLS.executeTool(ctx, tc.function.name, JSON.parse(tc.function.arguments));
        messages.push({ role: "tool", tool_call_id: tc.id, content: result });
    }
}
```
</CodeGroup>

## Context Prompt

The context includes available skills as XML:

```xml
<available_skills>
<skill>
<name>data-extraction</name>
<description>Extract structured data from documents</description>
</skill>
</available_skills>
```

## Tool Reference

### get_skill

```json
{"skill_name": "data-extraction"}
```

Returns: Skill ID, description, and file index with MIME types.

### get_skill_file

```json
{"skill_name": "data-extraction", "file_path": "SKILL.md"}
```

Returns: File content (text) or presigned URL (binary).

<Warning>
**Read-only:** These tools can only read skill content. To execute skill scripts, use [Sandbox Tools](/tool/bash_tools#mounting-skills).
</Warning>

## Next Steps

<CardGroup cols={3}>
<Card title="Skills API" icon="wand-magic-sparkles" href="/store/skill">
Upload and manage skills
</Card>
<Card title="Sandbox Tools" icon="terminal" href="/tool/bash_tools">
Execute skill scripts
</Card>
<Card title="Long-term Skill" icon="brain" href="/learn/quick">
Build long-term skills from agent sessions
</Card>
</CardGroup>
