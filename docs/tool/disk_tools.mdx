---
title: "Filesystem Tools"
description: "Enable LLMs to autonomously manage files on Acontext disks using function calling"
---

Acontext provides pre-built filesystem tools that allow LLMs to read, write, and manage files on disks through function calling. You can integrate these tools with OpenAI or Anthropic APIs to create agents that persist data autonomously.

## Available Tools

The SDK includes seven disk operation tools:

- **`write_file_disk`** - Create or overwrite text files
- **`read_file_disk`** - Read file contents with optional line offset and limit
- **`replace_string_disk`** - Find and replace text in files  
- **`list_disk`** - List files and directories in a path
- **`download_file_disk`** - Get a public URL to download a file
- **`grep_disk`** - Search file contents using regex patterns
- **`glob_disk`** - Find files by path pattern using glob syntax

<Tip>
These tools handle path normalization automatically and support nested directory structures like `/notes/`, `/documents/2024/`, etc.
</Tip>

## Building an Agent with Filesystem

You can build an agentic loop where the LLM autonomously calls disk tools to complete file-related tasks. Here's a complete example:

<CodeGroup>
```python Python
import json
from acontext import AcontextClient
from acontext.agent.disk import DISK_TOOLS
from openai import OpenAI

# Initialize clients
acontext_client = AcontextClient(
    api_key=os.getenv("ACONTEXT_API_KEY"),
)

# If you're using self-hosted Acontext:
# acontext_client = AcontextClient(
#     base_url="http://localhost:8029/api/v1",
#     api_key="sk-ac-your-root-api-bearer-token",
# )
openai_client = OpenAI()

# Create a disk and tool context
disk = acontext_client.disks.create()
ctx = DISK_TOOLS.format_context(acontext_client, disk.id)

# Get tool schemas for OpenAI
tools = DISK_TOOLS.to_openai_tool_schema()
print(tools)
# Simple agentic loop
messages = [
    {
        "role": "user",
        "content": "Create a todo.md file with 3 tasks. Then give me the public download URL",
    }
]

while True:
    response = openai_client.chat.completions.create(
        model="gpt-4.1",
        messages=messages,
        tools=tools,
    )

    message = response.choices[0].message
    messages.append(message)

    # Break if no tool calls
    if not message.tool_calls:
        print(f"ü§ñ Assistant: {message.content}")
        break

    # Execute each tool call
    for tool_call in message.tool_calls:
        print(f"‚öôÔ∏è Called {tool_call.function.name}")
        result = DISK_TOOLS.execute_tool(
            ctx, tool_call.function.name, json.loads(tool_call.function.arguments)
        )
        print(f"üîç Result: {result}")
        messages.append(
            {"role": "tool", "tool_call_id": tool_call.id, "content": result}
        )

```

```typescript TypeScript
import { AcontextClient, DISK_TOOLS } from '@acontext/acontext';
import OpenAI from 'openai';

// Initialize clients
const acontextClient = new AcontextClient({
    apiKey: process.env.ACONTEXT_API_KEY,
});

// If you're using self-hosted Acontext:
// const acontextClient = new AcontextClient({
//     baseUrl: "http://localhost:8029/api/v1",
//     apiKey: "sk-ac-your-root-api-bearer-token",
// });
const openaiClient = new OpenAI({ apiKey: 'sk-your-openai-key' });

// Create a disk and tool context
const disk = await acontextClient.disks.create();
const ctx = DISK_TOOLS.formatContext(acontextClient, disk.id);

// Get tool schemas for OpenAI
const tools = DISK_TOOLS.toOpenAIToolSchema();
console.log(tools);
// Simple agentic loop
const messages = [
  {
    role: 'user',
    content: 'Create a todo.md file with 3 tasks. Then check the content in this file',
  },
];

while (true) {
  const response = await openaiClient.chat.completions.create({
    model: 'gpt-4.1',
    messages,
    tools,
  });
  
  const message = response.choices[0].message;
  messages.push(message);
  
  // Break if no tool calls
  if (!message.tool_calls) {
    console.log(`ü§ñ Assistant: ${message.content}`);
    break;
  }
  
  // Execute each tool call
  for (const toolCall of message.tool_calls) {
    console.log(`‚öôÔ∏è Called ${toolCall.function.name}`);
    const result = await DISK_TOOLS.executeTool(
      ctx,
      toolCall.function.name,
      JSON.parse(toolCall.function.arguments)
    );
    console.log(`üîç Result: ${result}`);
    messages.push({
      role: 'tool',
      tool_call_id: toolCall.id,
      content: result,
    });
  }
}
```
</CodeGroup>

<Info>
The agent will automatically call the appropriate tools (`write_file_disk`, `read_file_disk`, etc.) to complete your request, creating a fully autonomous file management system.
</Info>

## How It Works

<Steps>
<Step title="Initialize clients and create a disk">
  Set up both the Acontext client and your LLM client (OpenAI or Anthropic). Create a disk to store files.

  <CodeGroup>
  ```python Python
  from acontext import AcontextClient
  from acontext.agent.disk import DISK_TOOLS

  client = AcontextClient(
      api_key=os.getenv("ACONTEXT_API_KEY"),
  )
  disk = client.disks.create()
  ctx = DISK_TOOLS.format_context(client, disk.id)
  ```

  ```typescript TypeScript
  import { AcontextClient, DISK_TOOLS } from '@acontext/acontext';

  const client = new AcontextClient({
      apiKey: process.env.ACONTEXT_API_KEY,
  });
  const disk = await client.disks.create();
  const ctx = DISK_TOOLS.formatContext(client, disk.id);
  ```
  </CodeGroup>
</Step>

<Step title="Pass tools to LLM">
  Convert the disk tools to the schema format your LLM provider expects and pass them when calling the LLM.

  <CodeGroup>
  ```python Python
  # For OpenAI
  tools = DISK_TOOLS.to_openai_tool_schema()
  response = openai_client.chat.completions.create(
      model="gpt-4.1",
      messages=messages,
      tools=tools,  # Pass tools here
  )

  # For Anthropic
  tools = DISK_TOOLS.to_anthropic_tool_schema()
  response = anthropic_client.messages.create(
      model="claude-sonnet-4-20250514",
      messages=messages,
      tools=tools,  # Pass tools here
  )
  ```

  ```typescript TypeScript
  // For OpenAI
  const tools = DISK_TOOLS.toOpenAIToolSchema();
  const response = await openaiClient.chat.completions.create({
      model: 'gpt-4.1',
      messages,
      tools,  // Pass tools here
  });

  // For Anthropic
  const tools = DISK_TOOLS.toAnthropicToolSchema();
  const response = await anthropicClient.messages.create({
      model: 'claude-sonnet-4-20250514',
      messages,
      tools,  // Pass tools here
  });
  ```
  </CodeGroup>
</Step>

<Step title="Implement the agentic loop">
  Create a loop that stores messages to Acontext, executes tool calls, and feeds results back until the task is complete.

  **Executing Tools After LLM Response:**

  When the LLM responds with tool calls, iterate through each one and execute them using `DISK_TOOLS.execute_tool()` (Python) or `DISK_TOOLS.executeTool()` (TypeScript):

  <CodeGroup>
  ```python Python
  # Execute each tool call from the LLM response
  for tool_call in message.tool_calls:
      result = DISK_TOOLS.execute_tool(
          ctx,                                      # Tool context with disk ID
          tool_call.function.name,                  # Tool name (e.g., "write_file_disk")
          json.loads(tool_call.function.arguments)  # Parse arguments
      )
      # Add tool result back to message history
      messages.append({
          "role": "tool",
          "tool_call_id": tool_call.id,
          "content": result
      })
  ```

  ```typescript TypeScript
  // Execute each tool call from the LLM response
  for (const toolCall of message.tool_calls) {
      const result = await DISK_TOOLS.executeTool(
          ctx,                                      // Tool context with disk ID
          toolCall.function.name,                   // Tool name (e.g., "write_file_disk")
          JSON.parse(toolCall.function.arguments)   // Parse arguments
      );
      // Add tool result back to message history
      messages.push({
          role: 'tool',
          tool_call_id: toolCall.id,
          content: result,
      });
  }
  ```
  </CodeGroup>

  <Check>
  The loop continues until the LLM returns a message without tool calls, indicating the task is complete.
  </Check>
</Step>
</Steps>

## Tool Reference

### write_file_disk

Create or overwrite a text file on the disk.

**Parameters:**
- `filename` (required) - Name of the file, e.g., `"report.md"`
- `content` (required) - Text content to write to the file
- `file_path` (optional) - Directory path, e.g., `"/notes/"` (defaults to `"/"`)

**Returns:** Success message with file path

### read_file_disk

Read the contents of a text file from the disk.

**Parameters:**
- `filename` (required) - Name of the file to read
- `file_path` (optional) - Directory path where the file is located (defaults to `"/"`)
- `line_offset` (optional) - Starting line number (defaults to `0`)
- `line_limit` (optional) - Maximum number of lines to return (defaults to `100`)

**Returns:** File content with line range information

### replace_string_disk

Replace all occurrences of a string in a file.

**Parameters:**
- `filename` (required) - Name of the file to modify
- `old_string` (required) - String to be replaced
- `new_string` (required) - Replacement string
- `file_path` (optional) - Directory path where the file is located (defaults to `"/"`)

**Returns:** Number of replacements made

### list_disk

List all files and directories at a specified path.

**Parameters:**
- `file_path` (required) - Directory path to list, e.g., `"/notes/"` or `"/"`

**Returns:** List of files and directories

### download_file_disk

Get a public presigned URL to download a file.

**Parameters:**
- `filename` (required) - Name of the file to get the download URL for
- `file_path` (optional) - Directory path where the file is located (defaults to `"/"`)
- `expire` (optional) - URL expiration time in seconds (defaults to `3600`)

**Returns:** Presigned public URL for downloading the file

### grep_disk

Search for text patterns within file contents using **regex**. Only searches text-based files (code, markdown, JSON, CSV, etc.).

**Parameters:**
- `query` (required) - Regex pattern to search for (e.g., `"TODO.*"`, `"function.*calculate"`, `"import.*pandas"`)
- `limit` (optional) - Maximum number of results to return (defaults to `100`)

**Returns:** List of files matching the pattern

<Warning>
This uses **regex syntax**, not glob. In regex:
- `.*` means "any characters" (zero or more)
- `*` alone means "zero or more of the preceding character"

For example, `"test*"` matches "tes", "test", "testt" ‚Äî NOT "test-file". Use `"test.*"` to match "test-file".
</Warning>

<Tip>
Common patterns: `"TODO.*"` (TODO comments), `"#.*Summary"` (markdown headers), `"error"` (case-sensitive match), `"(?i)error"` (case-insensitive).
</Tip>

### glob_disk

Find files by **path pattern** using glob syntax. Use `*` for any characters, `?` for single character, `**` for recursive directories.

**Parameters:**
- `query` (required) - Glob pattern (e.g., `"**/*.md"` for all markdown files, `"*.txt"` for text files in root, `"/docs/**/*.md"` for markdown in docs)
- `limit` (optional) - Maximum number of results to return (defaults to `100`)

**Returns:** List of files matching the glob pattern

<Tip>
Use `glob_disk` to find files by extension or location, perfect for discovering files without knowing exact names.
</Tip>

<Warning>
All file operations are scoped to the specific disk. Ensure you create and configure the disk context correctly before executing tools.
</Warning>

<Note>
For async Python usage, see [Async Python Client](/chore/async_python#async-agentic-tools) which covers `async_format_context()` and `async_execute_tool()` methods.
</Note>

